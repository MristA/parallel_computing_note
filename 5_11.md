# 5月11日
* 1 对等模式下的MPI的不同的进程功能，地位和分工大致相似，代码也应该是相似的，所不同的只是操作的对象和数据，比如多个进程同时计算一个数组的不同部分和，各进程就是对等的
* 2 MPI（消息传递接口）适用于分布式内存编程，pthreads和openmp适用于共享内存编程，分布式内存中存在（核--内存）对，不同对之间的核内存访问有显著的延迟，共享内存编程各个核之间共享同一内存
* 3 GPU的并行计算模式使用SIMD，需要许多处理大量的数据来维持ALU的忙碌，可能在小问题上的性能较差，而且需要CPU的资源调度。
* 4 在同一时刻只能有一个线程执行的代码块称为临界区，如果有多个线程执行会产生不正确结果，比如对同一个全局变量的写操作就是有竞争条件的，不可以同时访问。
